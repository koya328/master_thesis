\chapter{考察}
\thispagestyle{plain}   % chapterの直後に必ず指定

この章では5章での実験やテストの結果を考察し，最終的に本研究の目的である，人間とAIの協調の限界・可能性について考察する．

\section{タスクの提示や会話機能の考察}\label{sec:gpt_res_investigation}
この節では，先述の\ref{sec:gpt_res_test}節の動作テストについて考察する．
\ref{sec:gpt_res_test}節では，{\mason}とプレイヤーが対話を行い，{\mason}は現在の進行度に合わせたタスクの提示や作業支援，質問への回答が可能であることを確認できた．

このことから，大規模言語モデルに対して現在の状態を正しく伝えることが可能であれば，次のタスクを提示できることが示唆された．
また，目標に寛解のない事柄などに関しても回答できる能力を有していることが示唆された．

LLMがプレイヤーが次に行うべきステップを提案し，ピッケルの作り方などプレイヤー未知のタスクについて指導できることは，ゲームを通じた学習サポートツールとしての応用も可能であることを示唆している．
このようなサポートツールとしての使い方であれば，特にコミュニケーションスキルや問題解決スキルを向上させることが可能であると示唆される．
また，プレイヤーがbotとの対話の方法のみを知ることができれば，人間の教育者を必要とせずAIとの対話によって自律的に学習ができる未来が考えられる．

しかし，稀に次に提示するタスクが適切ではないことや，質問に対する回答が間違っている結果が確認された．
大規模言語モデルは出力が一定ではなく，出力される結果が必ずしもあっているとは限らないという特徴があり，この結果もそのデメリットの影響を受けている考えられる．
したがって現状では，{\mason}が誤った情報を回答しないように，RAGの機能で知識に基づいた回答を行うようにすることや，{\mason}を扱うときも他の大規模言語モデルと同様に，結果を鵜呑みにせず事実確認を徹底する必要があると考えられる．

\section{構造物生成の考察}\label{sec:generate_investigation}
この節では，先述の\ref{sec:build_mode_generate}節及び各小節における実験結果を考察する．
\ref{sec:build_mode_generate}節では，ビルドモードによる構造物の生成が行われたが，その結果から，いくつかの特筆すべき傾向が存在した．

\ref{sec:ex4}節の実験では，ファインチューニングされたgpt-3.5-turboモデルを使用し，その結果から複雑な構造物を生成する能力が向上したことが示唆された．
しかし，その一方で問題も生じており，その一つが建物内部の構造を埋めてしまう現象である．
これは，gpt-3.5-turboが内部構造の設計を適切に行えない，という可能性を指摘している．
また，ファインチューニング前の同モデルで駅を生成した\ref{sec:ex1}節の実験でも同様の問題が見られ，チケットカウンター，ベンチ，標識等の配置が適切でない，という結果が得られている．

一方で，モデルが更新されたgpt-4やgpt-4-turboを用いた実験，\ref{sec:ex2}節および\ref{sec:ex3}節では，この問題は見られなかった．
ここでは，それらのモデルが内部空間を適切に設計し，窓を正しい位置に配置する能力を示していた．
これは，これらのモデルが空間把握能力を著しく向上させていると考えられる．

これらの結果から，gpt-3.5-turboは空間把握能力が限定的であり，このモデルをさらにファインチューニングしても，人間と同様に複雑な構造を構築する能力を獲得するのは難しいと推測することができる．
しかし，後継のgpt-4やgpt-4-turboを用いれば，より複雑な構造物の生成が可能になると期待される．
これらのファインチューニングが実現すれば，より高度な建造物生成が可能となり，人間により強い建築のインスピレーションなどを与える可能性があると考えられる．

\section{アンケートの考察}\label{sec:survey_investigation}
この節では，先述の\ref{sec:survey_result}節及び各小節における実験結果を考察する．
アンケートの結果はすべての回答の平均が3を超えていたことから，肯定的な意見を得ることができた．
その中でも，そう思う，どちらかというとそう思う，どちらかというとそう思わない，そう思わないの4段階の同じ指標で回答してもらった結果，表\ref{tab:answer2}の結果のみ平均3.47と高かったことから，botによって大規模言語モデルの新しい使い方を学べたことが示唆された．

\section{考察}
この節では，\ref{sec:gpt_res_investigation}節～\ref{sec:survey_investigation}節の考察をもとに本研究の目的である，人間とAIの協調の限界・可能性について考察する．

\ref{sec:gpt_res_investigation}節～\ref{sec:survey_investigation}節の考察から，
AIとの協調により，学習効果や創造的なインスピレーションを得られること目的として，botを作成した結果，タスクの提示や支援，構造物生成などテストレベルでの興味深い結果を得られることが判明した．
しかし，現状では提示されたタスクが必ずしも合っているとは限らないことや複雑な構造物を生成できないことなどの問題があり，実用段階に至るにはまだいくつかの発展が必要であるという課題が示唆された．

しかし近年の大規模言語モデルの発展は著しく，現状のgpt-4-turboでは空間把握能力を有していることが示唆されたため，gpt-4-turboなどのモデルがファインチューニング可能になることや，より高精度なモデルが登場することによって，
将来的にはコミュニケーションスキルや問題解決スキル，創造的なインスピレーションをAIから得られる可能性が考えられる．
%他の環境への適応